product {
    modules {
        sirius-biz {
            version = "${project.version}"
            build = "${build.number}"
            date = "${timestamp}"
            vcs = "${build.vcs.number}"
        }
    }
}

# sirius-biz provides a multitude of frameworks for different use-cases
# and implements them using different databases. Therefore by default
# all frameworks are disabled and have to be enabled by the application.
sirius.frameworks {

    # User-manager which supports multi-tenant applications
    biz.tenants = false

    # Enables the JDBC storage layer for tenants.
    biz.tenants-jdbc = false

    # Enables the MongoDB storage layer for tenants.
    biz.tenants-mongo = false

    # A framework for letting a user map codes to text values
    biz.code-lists = false

    # Enables the JDBC storage layer for code-lists.
    biz.code-lists-jdbc = false

    # Enables the MongoDB storage layer for code-lists.
    biz.code-lists-mongo = false

    # Utilizes Elasticsearch to store all recorded logs, incidents,
    # audit logs and mails
    biz.protocols = false

    # Provides a change log for all entities which include a JournalData
    biz.journal = false

    # Provides an ID Generator which can either use MongoDB or JDBC
    # to generate sequences of unique IDs
    biz.sequences = false

    # Provides distributed locks based on either the JVM, Redis or JDBC
    biz.locks = false

    # Provides a object store like API for storing files. This can either use
    # the file system or other storage facilities.
    biz.storage = false

    # Provides a replication system for stored objects by using a JDBC datasource as
    # metadata repository.
    biz.storage-replication-jdbc = false

    # Provides a replication system for stored objects by using a MongoDB as
    # metadata repository.
    biz.storage-replication-mongo = false

    # Provides a rate-limiting / firewall which is either based on Redis.
    biz.isenguard = false

    # Provides a framework to record and visualize the output of background processes.
    biz.processes = false

    # Provides a framework to execute all kinds of application defined jobs.
    biz.jobs = false

    # Provides a framework to execute planned / scheduled tasks which are stored in a JDBC database.
    biz.scheduler-jdbc = false

    # Provides a framework to execute planned / scheduled tasks which are stored in a MongoDB database.
    biz.scheduler-mongo = false

    # Provides a storage option to place execution flags in a JDBC database.
    biz.analytics-execution-flags-jdbc = false

    # Provides a storage option to place execution flags in a MongoDB.
    biz.analytics-execution-flags-mongo = false

    # Provides a storage option for metrics in a JDBC database.
    biz.analytics-metrics-jdbc = false

    # Provides a storage option for in a MongoDB.
    biz.analytics-metrics-mongo = false
}

# Place the local address of the node here, i.e. http://192.168.0.1
# If no address is given, we use the local address determined by the system
# (using: InetAddress.getLocalHost().getHostAddress()) - however, in some
# environments like Docker, this might yield an inappropriate address.
#
# This address has to be reachable from all other cluster nodes.
sirius.nodeAddress = ""

# Contains a local token which is used by the Cluster controller so that some APIs can be invoked without
# further authentication.
sirius.clusterToken = ""

# Contains settings for the built-in firewall and rate-limiting facility
isenguard {
    # Determines which limiter is used. By default we use a "smart" strategy,
    # which uses "redis" is available and otherwise switches to the "noop" limiter.
    limiter = "smart"

    # If the "Redis" limiter is used, the given redis database is used to store
    # the counters and blocked IPs. By default we use the "system" database,
    # which is the default redis.
    redisName = "system"

    # Contains an interval and limit per interval for each realm.
    # Note that the realm "http" is used to limit all notable
    # HTTP calls.
    limit {
        # Specifies the defaults for all realms unless noted otherwise.
        # By default IsenGuard is turned off.
        default {
            # Defines the check interval
            interval = 10m

            # Defines the max number of occurrences within the given inverval
            limit = 0

            # Declares which the "scope" value of this realm will be.
            # There are three standard types:
            # - ip:     Limiting by ip address
            # - tenant: Limiting by tenant id
            # - user:   Limiting by user id
            #
            # For all other kinds of realms, the type "custom" can be used.
            # Also, additional frameworks might define more types.
            type = "custom"
        }

        # Specifies the constraints for all HTTP requests. By default this
        # is turned off, as there is no way of knowing the usage pattern
        # of a specific application.
        http {
            interval = 0
            limit = 0
            type = "ip"
        }

        # Specifies the constraints for negative AuditLog events (wrong password etc).
        # Once this limit is hit, the calling IP will be blocked for ten minutes.
        security {
            interval = 2m
            limit = 50
            type = "ip"
        }
    }

}

health.limits {
    # If there is any lock held, we will report this - but there is no
    # sane limit how many locks can be considered healthy / unhealty
    locks-count.gray  = 1
    locks-count.warning  = 0
    locks-count.error = 0

    # We start to warn as soon as we encounter one long running lock
    # (held for at least 30min). As this can still be quite alright
    # we do not consider this critical (red)
    locks-long-running.gray = 0
    locks-long-running.warning = 1
    locks-long-running.error = 0

    # Monitors the utilization of the events buffer which is used by the
    # EventRecorder to permit batch inserts of recorded events into Clickhouse
    events-buffer-usage.gray = 0
    events-buffer-usage.warning = 80
    events-buffer-usage.error = 99

    # Number of active tasks (remains gray when zero). There is no limit
    # to warn about, as the number can be specified in the system configuration.
    active-distributed-tasks.gray = 1
    active-distributed-tasks.warning = 0
    active-distributed-tasks.error = 0
}

async {
    # Defines the maximal number of concurrent tasks executed for the
    # Distributed Tasks framework.
    executor.distributed-tasks {
        poolSize = 8

        # Having a queue would be pointless, as the WorkLoaderLoop only
        # tries to keep the available executors running but will not
        # schedule additional work.
        queueLength = 0
    }

    # Interctive jobs should actually execute quite instantly. Therefore
    # we only permit a low parallelism but a certain queue length for peak loads.
    executor.interactive-jobs {
        poolSize = 2
        queueLength = 100
    }

    distributed {
        # Configures the nature of the queues used to distribute tasks.
        queues {
            # Each queue needs to suppliy the following settings
            # example {
                # Contains the concurrency token to control node-local parallelism
                # concurrencyToken = SomeToken

                # Determines if the queue is prioritized or a FIFO queue
                # prioritized = false

                # For prioritized queues the penalty should approximately be
                # equal to the expected runtime of an average task. This time is
                # used to compute the effective execution priority once a task is
                # scheduled.
                # penaltyTime = 1 minute
            # }

            # Defines the queue used by the MetricsGuaranteedSchedulerExecutor when scheduling metrics.
            metrics-scheduler {
                concurrencyToken = "analytics"
                prioritized = false
            }

            # Defines the queue used by the MetricsGuaranteedBatchExecutor when executing batches of metrics tasks.
            metrics-batch {
                concurrencyToken = "analytics"
                prioritized = false
            }

            # Defines the queue used by the MetricsBestEffortSchedulerExecutor and MetricsBestEffortBatchExecutor
            # when scheduling and executing batches of "best effort" metrics tasks.
            #
            # These tasks are only scheduled if the queue is empty. Therefore, if the system is overloaded it may
            # skip some of the "best effort" tasks - but it will never skip a guaranteed task.
            metrics-best-effort {
                concurrencyToken = "analytics"
                prioritized = false
            }

            # Defines the queue used by the CheckBatchExecutor to execute DailyChecks and ChangeChecks.
            checks {
                concurrencyToken = "analytics"
                prioritized = false
            }

            # Defines the queue used by the DefaultBatchProcessTaskExecutor for miscellaneous jobs.
            jobs {
                # We use a simple token here so that the number of parallel jobs can be specified
                concurrencyToken = "small-jobs"

                # The queue will be prioritized
                prioritized = true

                # As we have no idea what the average runtime of a job in this queue might be, we default the penalty
                # time to one hour.
                penaltyTime = 1h
            }

            # Defines the queue used by the ImportBatchProcessTaskExecutor for import jobs.
            import-jobs {
                concurrencyToken = "large-jobs"
                prioritized = true
                penaltyTime = 2h
            }

            # Defines the queue used by the ExportBatchProcessTaskExecutor for export jobs.
            export-jobs {
                concurrencyToken = "large-jobs"
                prioritized = true
                penaltyTime = 30m
            }

            # Defines the queue used by the ReportBatchProcessTaskExecutor for report jobs.
            report-jobs {
                concurrencyToken = "small-jobs"
                prioritized = true
                penaltyTime = 30m
            }

            # Defines the queue used by the CheckBatchProcessTaskExecutor for check jobs.
            check-jobs {
                concurrencyToken = "small-jobs"
                prioritized = true
                penaltyTime = 1h
            }
        }

        # Configures concurrency tokens which are semaphores on each node and
        # control local parallelism. Note that a single token can be shared by
        # multiple queues.
        concurrency {
            # Specifies the maximal number of parallel small jobs.
            small-jobs = 4

            # Specifies the maximal number of parallel large jobs.
            large-jobs = 2

            # Specifies the maximal number of parallel analytical tasks.
            analytics = 2
        }
    }
}

# Provides a cluster wide controller for executing background jobs.
# NeighborhoodWatch uses Redis locks and timestamps to control the
# execution of background jobs across a cluster of nodes.
# Per job one for the following settings can be set:
# LOCAL    - the jobs runs on this node independently of the cluster
# CLUSTER  - the job may run on this node, but only on one node within the cluster at once
# DISABLED - the job is disabled on this node
orchestration {
    loop-elastic-auto-batch = LOCAL
    loop-event-processor = LOCAL
    loop-delay-line = LOCAL
    loop-distributed-tasks-work-loader = LOCAL
    loop-redis-limiter-cleanup = CLUSTER
    loop-job-scheduler = CLUSTER
    loop-storage-layer1-replication = CLUSTER
    task-protocols-cleaner = CLUSTER
    task-delete-execution-flags = CLUSTER
    task-analytical-engine = CLUSTER
    task-logs-cleanup = LOCAL
    task-storage-cleaner = CLUSTER
    task-cleanup-processes = CLUSTER
}



timer.daily {

    # Determines when protocols and journals are purged based on the given settings...
    protocols-cleaner = 2

    # Determines when old execution flags are purged...
    delete-execution-flags = 4

    # Determines when outdated files in the storage system are purged...
    storage-cleaner = 3

    # Determines when analytical tasks are scheduled...
    analytical-engine = 23

    # Determines when expires process logs are removed...
    cleanup-processes = 2

}

# Controls the storage duration of protocol entries
protocols {
    keep-logs = 30 days
    keep-incidents = 30 days
    keep-mails = 365 days
    keep-journal = 1000 days
    keep-neutral-audit-logs = 30 days
    keep-negative-audit-logs = 180 days
}

# The audit log can write additional logs to the system log.
# This can be used to preserve the audit logs in an external archive with a
# potentially longer storage period. By default this is disabled to not jam
# the system logs.
logging.audit = OFF

# Specifies the secret used to sign internal URLs for specific entities...
# An empty secret signals, that a new (local) secret es generated during startup...
controller.secret = ""

jobs.categories {
    import {
        label = "$JobCategory.import"
        priority = 100
        icon = "fa-upload"
    }
    export {
        label = "$JobCategory.export"
        priority = 200
        icon = "fa-download"
    }
    check {
        label = "$JobCategory.check"
        priority = 300
        icon = "fa-check-square-o"
    }
    report {
        label = "$JobCategory.report"
        priority = 400
        icon = "fa-line-chart"
    }
    misc {
        label = "$JobCategory.misc"
        priority = 500
        icon = "fa-cogs"
    }
}

# Defines default code lists known to the system.
code-lists {
    default {
        # Determines if unknown codes should be recorded automatically so that
        # they can be managed in the admin UI
        autofill = true

        # Determines if a single code list is shared accross all tenants. These code lists
        # are owned by the system tenant and should have "autofill" turned off for obvious
        # reasons.
        global = false

    }

    # Defines the list of salutations.
    salutations {
        name = "Salutations"
        description = "Contains all salutations known to the system"
    }

    # Defines the list of countries.
    countries {
        name = "Countries"
        description = "Contains all countries known to the system. A RegEx can be supplied as additional value which is used to verify ZIP codes"
    }
}

# Contains the configuration of the file / object store system.
storage {


    # Defines the base directory when storing buckets in disk.
    baseDir = "data/storage"

    # If using ImageMagick, consider a command like:
    # "convert ${src} -resize ${width}x${height}> -quiet -quality 89 -format ${imageFormat} -strip -colorspace RGB -background white ${extend} -flatten ${dest}"
    conversionCommand=""

    # Option for the conversion command to extend the image to a minimum size
    extendOption = "-gravity center -extent ${extendWidth}x${extendHeight}<"

    # Defines all buckets known to the system.
    buckets {
        default {
            # Defines the permission required to view the bucket in the management UI.
            permission = "permission-manage-files"

            # Determines if an object (file) can be created via the management UI.
            canCreate = false

            # Determines if an object (file) can be edited via the management UI.
            canEdit = false

            # Determines whether a search in a bucket should always use a like constraint.
            alwaysUseLikeSearch = false

            # Determines if an object (file) can be deleted via the management UI.
            canDelete = false

            # Determines if objects are automatically removed after N days. 0 means disabled.
            deleteFilesAfterDays = 0

            # Determines the storage engine used for the bucket.
            engine = "fs"
        }

        # A work directory / bucket is provided per tenant and can be used to in- and output files.
        # This is also visible in the built-in virtual file system (FTP server) to upload and download files.
        # To limit the number of files in this directory, old files (older than 30 days) are automatically removed.
        # Therefore this should not be used for permanent storage.
        work {
            canCreate = true
            canEdit = true
            canDelete = true
            deleteFilesAfterDays = 30
        }

        # Provides a temporary storage space which is automatically maintained (files are deleted after 30 days).
        tmp {
            permission = "permission-manage-admin-files"
            canCreate = true
            canEdit = true
            canDelete = true
            deleteFilesAfterDays = 30
        }

        # Defines storage for versioned files
        versioned-files {
            canCreate = false
            canEdit = false
            canDelete = false

            # number of versions kept from one versioned file
            # setting this number to 0 will keep all versions
            maxNumberOfVersions = 50
        }
    }

}

# Contains settings for the virtual file system.
storage {
    # Provides credentials for the S3 compatible stores managed by ObjectStores.
    s3 {
        stores {
            # Provides the default configuration shared by all stores.
            default {
                accessKey = ""
                secretKey = ""
                endPoint = ""
                bucketSuffix = ""
                pathStyleAccess = true

                # Specifies the signer to use. Leave empty to use the standard signer of the
                # current AWS SDK.
                signer = ""
                # Use the following setting for CEPH stores:
                # signer = "S3SignerType"
            }

            # By default a "system" store is used if no other name is given.
            # An application should provide a configuration for this store if ObjectStores are used.
            system {

            }
        }
    }

    # Contains settings for the physical storage layer which either persists objects onto
    # disk or into a S3 compatible store.
    layer1 {

        # Defines the replication settings
        replication {
            # Defines the number of replication tasks in a batch.
            batchSize = 25

            # Defines the max number of batches to queue.
            maxBatches = 100

            # Defines the duration for which a delete is delayed.
            replicateDeleteDelay = 45d

            # Defines the duration for which an update is delayed.
            replicateUpdateDelay = 5m

            # Contains the duration for which a retry of a failed replication task is delayed.
            retryReplicationDelay = 90m

            # Determines the max number of replication attempts before a task is considered as "failed".
            maxReplicationAttempts = 5
        }

        # Enumerates the physical storage spaces known to the system.
        spaces {
            # Defines the defaults shared by all spaces.
            default {
                # Defines the engine to use. This can be either "s3" or "fs".
                engine = "s3"

                # Defines the s3 store to use (defined in s3.stores)
                store = "system"

                # For the "fs" engine a baseDir can be defined where a spaces are placed unless configured
                # otherwise (see below).
                baseDir = "data/storage"

                # Defines an effective path to store object into when using the "fs" engine.
                # If left empty, the "baseDir" + space name is used as path.
                path = ""
            }
        }
    }

    layer3 {

        # Defines uplinks available to all tenants.
        roots {
            # Defines a file system uplink which makes part of the local file system visible to the VFS
            # fs {
            #    # Contains the name of the virtual directory
            #    name = "fs"
            #
            #    # Contains an optional short description of the mount point
            #    description = ""
            #
            #    # Defines the type of the uplink
            #    type = "fs"
            #
            #    # Determines if the directory is mounted readonly
            #    readonly = true
            #
            #    # Contains the base path to mount
            #    basePath = "/data/somewhere"
            # }

            # Defines a file system uplink which mount a CIFS share into the VFS
            # cifs {
            #     # Contains the name of the virtual directory
            #    name = "MyShare"
            #    # Contains an optional short description of the mount point
            #    description = "Some words of caution"
            #
            #    # Defines the type of the uplink
            #    type = "cifs"
            #
            #    # Determines if the directory is mounted readonly
            #    readonly = true
            #
            #    # Contains the smb url to the share
            #    url = "smb://filer.scireum.local/schrank/"
            #
            #    # Contains the domain to which the user belongs which is used to authentication
            #    domain = "scireum.local"
            #    # Contains the user used to mount the share
            #    user = ""
            #
            #    # Contains the password of the user
            #    password = ""
            # }
        }

        downlink {
            # Defines the settings of the built-in FTP server.
            ftp {
                # Specifies the port to listen on. Use 0 to disable the server or 21 to run it on the common FTP port.
                port = 0

                # Specifies the port range to listen on for the data connection in passive mode, use any by default
                # Examples:
                # 2300               only use port 2300 as the passive port
                # 2300-2399          use all ports in the range
                # 2300-              use all ports larger than 2300
                # 2300, 2305, 2400-  use 2300 or 2305 or any port larger than 2400
                passivePorts = ""

                # Specifies the IP address to bind to. Leave empty to use all IP addresses.
                bindAddress = ""

                # Specifies the IP address clients have to connect to in passive mode.
                passiveExternalAddress = ""

                # Specifies the max. login failures before disconnecting.
                maxLoginFailures = 5

                # Specifies the max. number of concurrent clients.
                maxClients = 100

                # Specifies the max. number of threads to utilize.
                maxThreads = 10

                # Specifies the idle timeout for connections.
                idleTimeout = 10m

                # Specifies the max. connections per IP.
                maxConnectionsPerIp = 5

                # Specifies the JKS keystore to use for FTPS.
                keystore = ""

                # Specifies the keystore password.
                keystorePassword = ""

                # Specifies the key alias to use.
                keyAlias = ""

                # Determines if FTPS should be forced or not.
                forceSSL = false
            }
        }
    }

}



security {

    passwordMinLength = 4
    passwordSaneLength = 6

    # Specifies for how long generated passwords should be displayed.
    showGeneratedPasswordFor = 5 days

    scopes.default {
        manager = "tenants"
        system-tenant = "1"
        loginCookieTTL = 90 days
        available-languages = []
    }

    permissions {
        permission-manage-system        : "Required for system tenant user accounts to manage system settings"
        permission-manage-tenants       : "Required to manage tenants of the system"
        permission-manage-user-accounts : "Required to manage user accounts"
        permission-delete-user-accounts : "Required to delete user accounts"
        permission-manage-code-lists    : "Required to manage code lists"
        permission-system-protocols     : "Required to view protocols like logs, errors, mails, all audit logs"
        permission-system-cluster       : "Required to view and manage the cluster state"
        permission-audit-logs           : "Required to view audit logs for the own tenant"
        permission-system-journal       : "Required to view the system journal"
        permission-select-tenant        : "Required to switch to another tenant"
        permission-select-user-account  : "Required to switch to another user"
        permission-tasks                : "Required to view all managed tasks"
        permission-execute-jobs         : "Required to execute jobs"
        permission-manage-scheduler     : "Required to plan and edit scheduled jobs"
        permission-manage-files         : "Required to manage well known buckets in the storage system"
        permission-manage-admin-files   : "Required to access administrative buckets in the storage system"
        permission-manage-processes     : "Required to view processes of other users within the same tenant"
        permission-manage-all-processes : "Required to view processes of all users and tenants"
        permission-view-rate-limits     : "Required to view tenant-wide rate limits"
        feature-user-account-config     : "Required (most probably as tenant permission) to provide custom configurations for user accounts"
    }

    roles = [ "user-administrator", "administrator", "jobs-manager", "jobs-execution", "file-manager" ]

    tenantPermissions = [
    ]

    profiles {

        # If a user belongs to the system tenant, we set the member&affiliate flag
        "flag-system-tenant" {
            priority = 50
            flag-system-tenant-member = true
            flag-system-tenant-affiliate = true
        }

        # If a user is "user-administrator" of the system tenant we consider this to be a fully fledged system administrator.
        "flag-system-tenant-member+user-administrator" {
            priority = 60
            flag-system-administrator = true
        }

        flag-system-administrator {
            priority = 110
            permission-manage-tenants = true
            permission-manage-code-lists = true
            permission-system-protocols = true
            permission-system-cluster = true
            permission-system-journal = true
            permission-system-console = true
            permission-system-timing = true
            permission-system-notify-state = true
            permission-system-load = true
            permission-tasks = true
            permission-manage-all-processes = true
            permission-view-rate-limits = true
            permission-delete-user-accounts = true

            # By default we only permit sys admins to change the configs of any user in any
            # tenant as this is quite a specific and dangerous task...
            feature-user-account-config = true
        }

        user-administrator {
            priority = 120
            permission-manage-user-accounts = true
            permission-select-user-account = true
        }

        administrator {
            priority = 130
            permission-select-tenant = true
            permission-execute-jobs = true
            permission-manage-scheduler = true
            permission-view-scope-default-config = true
            permission-manage-files = true
            permission-manage-admin-files = true
            permission-system-audit-logs = true
            permission-manage-processes = true
            permission-view-rate-limits = true
        }

        jobs-manager {
            priority = 140
            permission-execute-jobs = true
            permission-manage-scheduler = true
            permission-manage-processes = true
        }

        jobs-execution {
            priority = 150
            permission-execute-jobs = true
        }

        file-manager {
            priority = 160
            permission-manage-files = true
        }
    }

    # defines the packages and upgrades for the different scopes
    packages {

        #The 'tenant' scope used by the tenants framework (TenantUserManager etc.)
        tenant {
            # the packages of the scope
            packages = []

            # the upgrades of the scope
            upgrades = []
        }

        # indicates which permissions are needed to show a specific permission for a user
        # permissions which have no requirements can be omitted
        # have to be key-value pairs, in which the key is the permission in question and the value is the required permission
        required-permissions-for-permission {

        }
    }
}

# Specifies cache sizes used by the biz platform
cache {

    tenants-users {
        maxSize = 100
        ttl = 1 hour
    }

    tenants-roles {
        maxSize = 100
        ttl = 1 hour
    }

    tenants-children {
        maxSize = 256
        ttl = 1 hour
    }

    tenants-tenants {
        maxSize = 32
        ttl = 1 hour
    }

    tenants-configs {
        maxSize = 100
        ttl = 1 hour
    }

    storage-object-metadata {
        maxSize = 16384
        ttl = 1 hour
    }

    virtual-objects {
        maxSize = 16384
        ttl = 1 hour
    }

    processes-first-level {
        maxSize = 128
        ttl = 10 seconds
    }

    processes-second-level {
        maxSize = 256
        ttl = 10 minutes
    }

    standby-processes {
        maxSize = 1024
        ttl = 1 hour
    }

    codelists-values {
        maxSize = 4096
        ttl = 1 hour
    }

    objectstores-buckets {
        maxSize = 128
        ttl = 1 hour
    }
}

# Specifies thread pools used by the biz platform
async.executor {
    # This work queue is shared by all transfer managers across all object stores and
    # used for multipart up- and downloads.
    s3 {
        poolSize = 10
        queueLength = 0
    }
}

# By default we use the smart lock manager. This detects the presence of redis and uses cluster-wide locks
# or otherwise uses fast local locks within the JVM. to enforce local locks, use "java".
# Another approach for clusters without Redis is using an SQL Database to implement locks distributed locks
# which is available via "sql" (SQLLockManager).
locks.manager = "smart"

# Determines how "Sequences" are stored and computed. By default a "smart" strategy is used which either
# checks if a "sql" database or a "mongo" database is ready and picks the right strategy. If both are
# available the effective startegy can be determined by setting an explicit value here.
sequences.strategy = "smart"

# Provides some aliases to simplify importing user accounts
importer.aliases {
    sqluseraccount {
        userAccountData_email: [ "email", "$Model.email" ]
        userAccountData_externalLoginRequired: [ "externalLoginRequired", "$UserAccount.externalLoginRequired" ]
        userAccountData_person_title: [ "title", "$PersonData.title" ]
        userAccountData_person_salutation: [ "salutation", "$PersonData.salutation" ]
        userAccountData_person_firstname: [ "firstname", "$PersonData.firstname" ]
        userAccountData_person_lastname: [ "lastname", "$PersonData.lastname" ]
        userAccountData_login_username: [ "username", "user", "$LoginData.username" ]
        userAccountData_login_generatedPassword: [ "password", "$LoginData.generatedPassword", "$LoginData.password" ]
        userAccountData_login_accountLocked: [ "locked", "$LoginData.accountLocked" ]
        userAccountData_permissions_permissions: [ "roles", "permissions", "$PermissionData.permissions" ]
    }

    mongouseraccount {
        userAccountData_email: [ "email", "$Model.email" ]
        userAccountData_externalLoginRequired: [ "externalLoginRequired", "$UserAccount.externalLoginRequired" ]
        userAccountData_person_title: [ "lastname", "$PersonData.title" ]
        userAccountData_person_salutation: [ "salutation", "$PersonData.salutation" ]
        userAccountData_person_firstname: [ "firstname", "$PersonData.firstname" ]
        userAccountData_person_lastname: [ "lastname", "$PersonData.lastname" ]
        userAccountData_login_username: [ "username", "user", "$LoginData.username" ]
        userAccountData_login_generatedPassword: [ "password", "$LoginData.generatedPassword", "$LoginData.password" ]
        userAccountData_login_accountLocked: [ "locked", "$LoginData.accountLocked" ]
        userAccountData_permissions_permissions: [ "roles", "permissions", "$PermissionData.permissions" ]
    }
}

# Determines which databases can be directly queried via /system/sql
# By default we allow to access the system database and clickhouse, which is the statistics database.
# Note that if a database is listed here, but not present, it will be ignored.
jdbc.selectableDatabases = [ system, clickhouse ]

mixing.legacy.SQLTenant.rename {
    "tenantData_configString": "tenantData_permissions_configString"
    "tenantData_packageData_additionalPermissions": "tenantData_permissions_permissionString"
}

mixing.legacy.SQLUserAccount.rename {
    "userAccountData_permissions_permissions": "userAccountData_permissions_permissionString"
}
